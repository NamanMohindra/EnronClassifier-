{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Response Generation(9).ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO9ep+lVD8e3EbdzkY9+e8w",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NamanMohindra/EnronClassifier-/blob/master/Response_Generation(9).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_vPncf6twmg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "outputId": "4c1ec657-24fd-472d-d667-8997901f86c9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3FeCg43tzHC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        },
        "outputId": "f475b536-f46a-48ac-efec-dc7e648e27a6"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from sklearn.svm import LinearSVC\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.utils import to_categorical"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OeChfmN4uC1A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess(x, y):\n",
        "  x = tf.cast(x, tf.float32) / 255.0 #normalization\n",
        "  y = tf.cast(y, tf.int64)\n",
        "\n",
        "  return x, y\n",
        "\n",
        "def create_dataset(xs, ys, n_classes=10):\n",
        "  ys = tf.one_hot(ys, depth=n_classes)\n",
        "  return tf.data.Dataset.from_tensor_slices((xs, ys)) \\\n",
        "    .map(preprocess) \\\n",
        "    .shuffle(len(ys)) \\\n",
        "    .batch(500)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GeyVPaBauGVm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        },
        "outputId": "0abfb427-0152-4546-9bbb-73f2a35964b9"
      },
      "source": [
        "#TRAINING\n",
        "\n",
        "ENRONFOLDER = 'drive/My Drive/Enron Spam/'\n",
        "ENRONNOSPAMDATASET = 'drive/My Drive/Enron Spam/ham'\n",
        "#fetching the feature vectors and annotation labels plus indices \n",
        "ANNO_LOC = 'drive/My Drive/Enron Spam/annotations.npy'\n",
        "ANNOIND_LOC = 'drive/My Drive/Enron Spam/annotation_indices.npy'\n",
        "CONTEXT_LOC = 'drive/My Drive/Enron Spam/context_annotations.npy'\n",
        "CONTEXTIND_LOC = 'drive/My Drive/Enron Spam/context_annotation_indices.npy'\n",
        "FEATURES_LOC = 'drive/My Drive/Enron Spam/featureVectors.npy'\n",
        "\n",
        "print(\"All vectors loaded!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All vectors loaded!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLlnRlC8uKpx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feature_vectors = np.load(FEATURES_LOC)\n",
        "formal_informal_annotations = np.load(ANNO_LOC)\n",
        "formal_informal_indices = np.load(ANNOIND_LOC)\n",
        "context_annotations = np.load(CONTEXT_LOC)\n",
        "context_annotations_indices = np.load(CONTEXTIND_LOC)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "543Id5z8uPPl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        },
        "outputId": "285923b1-af39-49e2-f329-93bdddf85dd8"
      },
      "source": [
        "print(len(feature_vectors))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3691\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbM6qnAeuVHd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#storing feature vectors of 50 annotated emails in X_train\n",
        "formal_informal_X = []\n",
        "for each_index in formal_informal_indices:\n",
        "  formal_informal_X.append(feature_vectors[each_index])\n",
        "X_TRAIN_1 = np.asarray(formal_informal_X)\n",
        "#storing annoations of 50 emails in Y_Train\n",
        "Y_LOAD = [each_element for each_element in formal_informal_annotations]\n",
        "Y_TRAIN_1 = to_categorical(Y_LOAD)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_SlQtjdvZFz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#storing feature vectors of 50 annotated emails in X_train \n",
        "context_X = []\n",
        "for each_index in context_annotations_indices:\n",
        "  context_X.append(feature_vectors[each_index])\n",
        "#0 as 1000,1 as 0100, 2 as 0010 and 3 as 0001\n",
        "X_TRAIN_2 = np.asarray(context_X)\n",
        "Y_TRAIN_2 = to_categorical(context_annotations)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kykAU1a9vb-2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        },
        "outputId": "24c1dc4d-a212-458f-c047-9a571f016e3e"
      },
      "source": [
        "print(np.shape(X_TRAIN_1))\n",
        "print(np.shape(Y_TRAIN_1))\n",
        "print(np.shape(X_TRAIN_2))\n",
        "print(np.shape(Y_TRAIN_2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50, 1000)\n",
            "(50, 2)\n",
            "(50, 1000)\n",
            "(50, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwDyr-lEvjUV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "outputId": "f5d969ab-8607-4b57-8761-089b9e65f458"
      },
      "source": [
        "#MODEL 1: Formal-Informal_Classifier\n",
        "\n",
        "model1 = tf.keras.Sequential([\n",
        "# Adds a densely-connected layer with 64 units to the model:\n",
        "layers.Dense(64, activation='relu', input_shape=(1000,)),\n",
        "# Add another:\n",
        "layers.Dense(64, activation='relu'),\n",
        "# Add an output layer with 2 output units:\n",
        "layers.Dense(2, activation='softmax')])\n",
        "\n",
        "model1.compile(optimizer=tf.keras.optimizers.Adam(0.01),\n",
        "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model1.fit(X_TRAIN_1, Y_TRAIN_1, epochs=10, batch_size=32)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.6790 - accuracy: 0.5800\n",
            "Epoch 2/10\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.5381 - accuracy: 0.6600\n",
            "Epoch 3/10\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.4318 - accuracy: 1.0000\n",
            "Epoch 4/10\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3798 - accuracy: 0.9800\n",
            "Epoch 5/10\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3542 - accuracy: 0.9800\n",
            "Epoch 6/10\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3420 - accuracy: 0.9800\n",
            "Epoch 7/10\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.3348 - accuracy: 0.9800\n",
            "Epoch 8/10\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.3296 - accuracy: 0.9800\n",
            "Epoch 9/10\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.3276 - accuracy: 0.9800\n",
            "Epoch 10/10\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.3260 - accuracy: 0.9800\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f68f548c0f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDHyrmOCv5Yh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "outputId": "f435ef5d-0387-467b-9246-74b3ba089c3d"
      },
      "source": [
        "#MODEL 2: Context_Classifier\n",
        "\n",
        "model2 = tf.keras.Sequential([\n",
        "# Adds a densely-connected layer with 64 units to the model:\n",
        "layers.Dense(64, activation='relu', input_shape=(1000,)),\n",
        "# Add another:\n",
        "layers.Dense(100, activation='relu'),\n",
        "# Add an output layer with 4 output units:\n",
        "layers.Dense(4, activation='softmax')])\n",
        "\n",
        "model2.compile(optimizer=tf.keras.optimizers.Adam(0.01),\n",
        "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model2.fit(X_TRAIN_2, Y_TRAIN_2, epochs=10, batch_size=25)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 1.3559 - accuracy: 0.2800\n",
            "Epoch 2/10\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 1.1751 - accuracy: 0.6200\n",
            "Epoch 3/10\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.9916 - accuracy: 0.7800\n",
            "Epoch 4/10\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.9013 - accuracy: 0.8600\n",
            "Epoch 5/10\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.8335 - accuracy: 0.9400\n",
            "Epoch 6/10\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.7710 - accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.7574 - accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.7524 - accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.7488 - accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 0.7476 - accuracy: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f68f2606828>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTfgLOicwAqW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Generating Responses for random mails:\n",
        "\n",
        "def fetchLabel(mailIndex):\n",
        "  twoD_array = []\n",
        "  classification1 = \"\"\n",
        "  classification2 = \"\"\n",
        "  responseHeader = \"\"\n",
        "  responseFooter = \"\"\n",
        "  R1 = []\n",
        "  R2 = []\n",
        "  feature_vector = feature_vectors[mailIndex]\n",
        "  twoD_array.append(feature_vector)\n",
        "  file_location = os.listdir(ENRONNOSPAMDATASET)[mailIndex]\n",
        "  FILENAME = os.path.join(ENRONNOSPAMDATASET, file_location)\n",
        "  DD = np.asarray(twoD_array)\n",
        "  with open(FILENAME, 'r',encoding='utf-8',errors='ignore') as myfile:\n",
        "    data = myfile.read()\n",
        "    print(\"Message Contents: \")\n",
        "    print(data)\n",
        "\n",
        "    result1 = model1.predict(DD)\n",
        "    #converting to normal array\n",
        "    R1 = [x for x in result1[0]]\n",
        "    #returning max index(if 0 then formal, if 1 then informal)\n",
        "    #finding which neuron has more activation \n",
        "    maxInd1 = R1.index(max(R1))\n",
        "    if(maxInd1==0):\n",
        "      classification1=\"formal\"\n",
        "      responseFooter = \"Yours Sincerely..\"\n",
        "    elif(maxInd1==1):\n",
        "      classification1=\"informal\"\n",
        "      responseFooter = \"Regards..\"\n",
        "    else:\n",
        "      print(\"Error in Formal-Informal Classification\")\n",
        "    \n",
        "    result2 = model2.predict(DD)\n",
        "    R2 = [y for y in result2[0]]\n",
        "    #finding which neuron has maximum activation\n",
        "    #NN returns 1 2D array with 1 one-D array inside it, we find the corresponding max ind\n",
        "    maxInd2 = R2.index(max(R2))\n",
        "    if(maxInd2==0):\n",
        "      classification2=\"affirmative\"\n",
        "      responseHeader = \"(a) Thank You, I will look into it (b) Thank you for informing\"\n",
        "    elif(maxInd2==1):\n",
        "      classification2=\"proposal\"\n",
        "      responseHeader = \"(a) Sure, we can proceed (b) I am not sure we can proceed\"\n",
        "    elif(maxInd2==2):\n",
        "      classification2=\"followup\"\n",
        "      responseHeader=\"(a) Okay, I will follow up as required (b) Unfortunately, I am unable to follow up\"\n",
        "    elif(maxInd2==3):\n",
        "      classification2=\"invite\"\n",
        "      responseHeader=\"(a) Thank You, I will be there (b) Thank you, but I won't be able to make it\"\n",
        "    else:\n",
        "      print(\"Error in context classification\")\n",
        "\n",
        "    fetch_results = [classification1,classification2]\n",
        "\n",
        "    #generating response based on category:\n",
        "\n",
        "    print(\"\\nResponse:\")\n",
        "    print(responseHeader)\n",
        "    print(responseFooter)\n",
        "\n",
        "    return fetch_results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LuU-Xf7VwGE1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "84237ac0-cfbc-471a-f747-7e3d9387a975"
      },
      "source": [
        "genIndex = random.randrange(3000)\n",
        "fetchLabel(genIndex)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Message Contents: \n",
            "Subject: re : boat\n",
            "i believe the boat is 18 to 19 ft long and i do have a boat cover . i will bring the boat information with me tomorrow for anymore questions . i recently took it to the shop to get it ready for this season and the salesman said it looked brand new . it has a brand new battery and everything runs perfectly . call me if you want to take a look at it .\n",
            "briant\n",
            "66459\n",
            "\n",
            "Response:\n",
            "(a) Thank You, I will look into it (b) Thank you for informing\n",
            "Regards..\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['informal', 'affirmative']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBNgUGgCWtZW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}