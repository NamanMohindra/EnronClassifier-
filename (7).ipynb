{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ActiveTesting.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPlichjQJ9uBuk2FUIDLINy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NamanMohindra/EnronClassifier-/blob/master/(7).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DotcgiE9SEGc",
        "colab_type": "code",
        "outputId": "8f0bd008-a1e7-412e-dbb7-b62abc48ef1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "!pip install tensorflow-gpu==2.0.1-alpha0\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow-gpu==2.0.1-alpha0 (from versions: 0.12.1, 1.0.0, 1.0.1, 1.1.0, 1.2.0, 1.2.1, 1.3.0, 1.4.0, 1.4.1, 1.5.0, 1.5.1, 1.6.0, 1.7.0, 1.7.1, 1.8.0, 1.9.0, 1.10.0, 1.10.1, 1.11.0, 1.12.0, 1.12.2, 1.12.3, 1.13.1, 1.13.2, 1.14.0, 1.15.0rc0, 1.15.0rc1, 1.15.0rc2, 1.15.0rc3, 1.15.0, 1.15.2, 1.15.3, 2.0.0a0, 2.0.0b0, 2.0.0b1, 2.0.0rc0, 2.0.0rc1, 2.0.0rc2, 2.0.0, 2.0.1, 2.0.2, 2.1.0rc0, 2.1.0rc1, 2.1.0rc2, 2.1.0, 2.1.1, 2.2.0rc0, 2.2.0rc1, 2.2.0rc2, 2.2.0rc3, 2.2.0rc4, 2.2.0)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for tensorflow-gpu==2.0.1-alpha0\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQSrRVtFSXDQ",
        "colab_type": "code",
        "outputId": "fe3e8a7f-f864-4127-9ee3-21b53320fe1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmCNMSRAcX8I",
        "colab_type": "code",
        "outputId": "71f54a8f-a1a9-4f71-f0bf-086161510165",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 710
        }
      },
      "source": [
        "!pip install --upgrade tensorflow\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: tensorflow in /usr/local/lib/python3.6/dist-packages (2.2.0)\n",
            "Requirement already satisfied, skipping upgrade: tensorflow-estimator<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.2.0)\n",
            "Requirement already satisfied, skipping upgrade: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.29.0)\n",
            "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.1)\n",
            "Requirement already satisfied, skipping upgrade: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.3.3)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.2.1)\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.34.2)\n",
            "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.2.1)\n",
            "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.18.4)\n",
            "Requirement already satisfied, skipping upgrade: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.10.0)\n",
            "Requirement already satisfied, skipping upgrade: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.9.0)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.7.2)\n",
            "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (0.4.1)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.6.0.post3)\n",
            "Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (46.3.0)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (3.2.2)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (0.2.8)\n",
            "Requirement already satisfied, skipping upgrade: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.1.1)\n",
            "Requirement already satisfied, skipping upgrade: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (4.0)\n",
            "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow) (1.3.0)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (2020.4.5.1)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (2.9)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow) (1.6.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (0.4.8)\n",
            "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPMdNlK4Stm1",
        "colab_type": "code",
        "outputId": "8597e298-5586-4287-9514-c5147882b2b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        }
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from sklearn.svm import LinearSVC\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.utils import to_categorical"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcfULPjmTRbq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess(x, y):\n",
        "  x = tf.cast(x, tf.float32) / 255.0\n",
        "  y = tf.cast(y, tf.int64)\n",
        "\n",
        "  return x, y\n",
        "\n",
        "def create_dataset(xs, ys, n_classes=10):\n",
        "  ys = tf.one_hot(ys, depth=n_classes)\n",
        "  return tf.data.Dataset.from_tensor_slices((xs, ys)) \\\n",
        "    .map(preprocess) \\\n",
        "    .shuffle(len(ys)) \\\n",
        "    .batch(500)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4-Z_Rp9UOGL",
        "colab_type": "code",
        "outputId": "dbc42288-2d85-4571-cd7a-6cdbfca5d247",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        }
      },
      "source": [
        "ENRONFOLDER = 'drive/My Drive/Enron Spam/'\n",
        "ANNO_LOC = 'drive/My Drive/Enron Spam/annotations.npy'\n",
        "ANNOIND_LOC = 'drive/My Drive/Enron Spam/annotation_indices.npy'\n",
        "FEATURES_LOC = 'drive/My Drive/Enron Spam/featureVectors.npy'\n",
        "ENRONNOSPAMDATASET = 'drive/My Drive/Enron Spam/ham'\n",
        "\n",
        "features = np.load(FEATURES_LOC)\n",
        "ANNO = np.load(ANNOIND_LOC)\n",
        "X_train = []\n",
        "for each_index in ANNO:\n",
        "  X_train.append(features[each_index])\n",
        "Y_load = np.load(ANNO_LOC)\n",
        "\n",
        "Y_train = [each for each in Y_load]\n",
        "\n",
        "model1 = LinearSVC()\n",
        "model1.fit(X_train, Y_train)\n",
        "\n",
        "\n",
        "y_binary = to_categorical(Y_train)\n",
        "\n",
        "XT = np.asarray(X_train)\n",
        "print(np.shape(XT))\n",
        "print(np.shape(y_binary))\n",
        "\n",
        "\n",
        "model2 = tf.keras.Sequential([\n",
        "# Adds a densely-connected layer with 64 units to the model:\n",
        "layers.Dense(64, activation='relu', input_shape=(1000,)),\n",
        "# Add another:\n",
        "layers.Dense(64, activation='relu'),\n",
        "# Add an output layer with 2 output units:\n",
        "layers.Dense(2, activation='softmax')])\n",
        "\n",
        "model2.compile(optimizer=tf.keras.optimizers.Adam(0.01),\n",
        "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model2.fit(XT, y_binary, epochs=10, batch_size=32)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50, 1000)\n",
            "(50, 2)\n",
            "Epoch 1/10\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6982 - accuracy: 0.4000\n",
            "Epoch 2/10\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.5434 - accuracy: 0.7000\n",
            "Epoch 3/10\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.4480 - accuracy: 0.8400\n",
            "Epoch 4/10\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.3958 - accuracy: 0.9800\n",
            "Epoch 5/10\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3606 - accuracy: 1.0000\n",
            "Epoch 6/10\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.3455 - accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.3348 - accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.3294 - accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.3248 - accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.3223 - accuracy: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa1f008b8d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHACLeKyNxAG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#TESTING\n",
        "def fetchLabel(mailIndex):\n",
        "  twoD_array = []\n",
        "  feature_vector = features[mailIndex]\n",
        "  twoD_array.append(feature_vector)\n",
        "  file_location = os.listdir(ENRONNOSPAMDATASET)[mailIndex]\n",
        "  FILENAME = os.path.join(ENRONNOSPAMDATASET, file_location)\n",
        "  with open(FILENAME, 'r',encoding='utf-8',errors='ignore') as myfile:\n",
        "    data = myfile.read()\n",
        "    #print(\"Message Contents: \")\n",
        "    #print(data)\n",
        "    #print(\"Classifier Label: \")\n",
        "    result1 = model1.predict(twoD_array)[0]\n",
        "    DD = np.asarray(twoD_array)\n",
        "    #print(np.shape(DD))\n",
        "    result2 = model2.predict(DD)\n",
        "    fetch_results = [result1,result2]\n",
        "    return fetch_results"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hFq8OcyN12u",
        "colab_type": "code",
        "outputId": "e4bf639a-6afb-4cda-db41-765712306b5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "results1 = []\n",
        "results2 = []\n",
        "for x in range(15):\n",
        "  labels = fetchLabel(x)\n",
        "  results1.append(labels[0])\n",
        "  results2.append(labels[1])\n",
        "print(results1)\n",
        "print(results2)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1]\n",
            "[array([[0.99673283, 0.00326717]], dtype=float32), array([[0.9975816 , 0.00241837]], dtype=float32), array([[3.227840e-04, 9.996772e-01]], dtype=float32), array([[0.8966477 , 0.10335236]], dtype=float32), array([[0.8966477 , 0.10335236]], dtype=float32), array([[0.9975816 , 0.00241837]], dtype=float32), array([[9.9999952e-01, 4.1740518e-07]], dtype=float32), array([[9.9999881e-01, 1.1627278e-06]], dtype=float32), array([[0.02156892, 0.97843105]], dtype=float32), array([[0.02156892, 0.97843105]], dtype=float32), array([[0.8604027 , 0.13959733]], dtype=float32), array([[0.9909507 , 0.00904931]], dtype=float32), array([[0.9909507 , 0.00904931]], dtype=float32), array([[0.8604027 , 0.13959733]], dtype=float32), array([[4.988102e-04, 9.995012e-01]], dtype=float32)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrXiYkW7N5Bn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}