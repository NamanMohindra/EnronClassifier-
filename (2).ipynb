{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TrainingTestingData(Spam-NoSpam)(2).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPveMGroa1uHnk44oYceodo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NamanMohindra/EnronClassifier-/blob/master/(2).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqIQYw_hccBS",
        "colab_type": "code",
        "outputId": "de3a3ba8-8868-441f-b4b7-bd382b9cc7f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 189
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rs6QvlnydNvi",
        "colab_type": "code",
        "outputId": "cb5bc44d-6b85-4552-f0b3-4ff7a3fb2384",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "import csv\n",
        "import re\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('words')\n",
        "from pprint import pprint\n",
        "from sklearn.utils import shuffle"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JtwuCVKeGL2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#SUPERVISED LEARNING\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DqR-UlAeRv2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "def generateVector(mail_string,bagofwords):\n",
        "  mail_vector = np.zeros(1000)\n",
        "  res = re.findall(r'\\w+', mail_string)\n",
        "  res.pop(0)\n",
        "  final_res = []\n",
        "  for each_word in res:\n",
        "    if ((each_word.isalpha()) and (each_word not in stop_words)) :\n",
        "      final_res.append(each_word)\n",
        "  vector_counter = 0\n",
        "  for each_word in bagofwords:\n",
        "    if each_word in final_res:\n",
        "      mail_vector[vector_counter]=1\n",
        "    vector_counter+=1\n",
        "\n",
        "  return mail_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-StbYzSleUTM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Import Bag of Words csv\n",
        "#Create training and testing data\n",
        "\n",
        "X_train = []\n",
        "Y_train = []\n",
        "X_test = []\n",
        "Y_test = []\n",
        "\n",
        "ENRONSPAMDATASET = 'drive/My Drive/Enron Spam/spam'\n",
        "ENRONNOSPAMDATASET = 'drive/My Drive/Enron Spam/ham'\n",
        "BAGOFWORDS = 'drive/My Drive/Enron Spam/bagofwords.csv'\n",
        "\n",
        "bagofwords_data = pd.read_csv(BAGOFWORDS)\n",
        "bagofwords = bagofwords_data[bagofwords_data.columns[0]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CxRaQp3eXwB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Adding Spam Mails to X_test and Y_test\n",
        "\n",
        "file_list = os.listdir(ENRONSPAMDATASET)[1000:]\n",
        "for each_file in file_list:\n",
        "  FILENAME = os.path.join(ENRONSPAMDATASET, each_file)\n",
        "  with open(FILENAME, 'r',encoding='utf-8',errors='ignore') as myfile:\n",
        "    data = myfile.read()\n",
        "    mail_vector = generateVector(data,bagofwords)\n",
        "    X_test.append(mail_vector)\n",
        "    Y_test.append(1)\n",
        "\n",
        "#Adding Non Spam Mails to X_test and Y_test\n",
        "\n",
        "file_list = os.listdir(ENRONNOSPAMDATASET)[3000:]\n",
        "for each_file in file_list:\n",
        "  FILENAME = os.path.join(ENRONNOSPAMDATASET, each_file)\n",
        "  with open(FILENAME, 'r',encoding='utf-8',errors='ignore') as myfile:\n",
        "    data = myfile.read()\n",
        "    mail_vector = generateVector(data,bagofwords)\n",
        "    X_test.append(mail_vector)\n",
        "    Y_test.append(0)\n",
        " \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBUJNtVbqZB9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Adding Spam Mails to X_train and Y_train\n",
        "\n",
        "file_list = os.listdir(ENRONSPAMDATASET)[0:1000]\n",
        "for each_file in file_list:\n",
        "  FILENAME = os.path.join(ENRONSPAMDATASET, each_file)\n",
        "  with open(FILENAME, 'r',encoding='utf-8',errors='ignore') as myfile:\n",
        "    data = myfile.read()\n",
        "    mail_vector = generateVector(data,bagofwords)\n",
        "    X_train.append(mail_vector)\n",
        "    Y_train.append(1)\n",
        "\n",
        "#Adding Non-Spam Mails to X_train and Y_train\n",
        "file_list = os.listdir(ENRONNOSPAMDATASET)[0:3000]\n",
        "for each_file in file_list:\n",
        "  FILENAME = os.path.join(ENRONNOSPAMDATASET, each_file)\n",
        "  with open(FILENAME, 'r',encoding='utf-8',errors='ignore') as myfile:\n",
        "    data = myfile.read()\n",
        "    mail_vector = generateVector(data,bagofwords)\n",
        "    X_train.append(mail_vector)\n",
        "    Y_train.append(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1qLpkjZe6-v",
        "colab_type": "code",
        "outputId": "e99a434e-0a84-4e25-c1d2-b2b6fb78454d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print(len(X_test))\n",
        "print(len(Y_test))\n",
        "print(len(Y_train))\n",
        "print(len(X_train))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1219\n",
            "1219\n",
            "4000\n",
            "4000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CAy5J-QFqp47",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test, Y_test = shuffle(X_test, Y_test)\n",
        "\n",
        "#saving numpy arrays\n",
        "XFile = 'drive/My Drive/Enron Spam/xtest.npy'\n",
        "np.save(XFile, X_test)\n",
        "\n",
        "YFile = 'drive/My Drive/Enron Spam/ytest.npy'\n",
        "np.save(YFile, Y_test)\n",
        "\n",
        "XFile = 'drive/My Drive/Enron Spam/xtrain.npy'\n",
        "np.save(XFile, X_train)\n",
        "\n",
        "YFile = 'drive/My Drive/Enron Spam/ytrain.npy'\n",
        "np.save(YFile, Y_train)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}